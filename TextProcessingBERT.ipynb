{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "#!pip3 install https://download.pytorch.org/whl/cpu/torch-1.0.1-cp37-cp37m-win_amd64.whl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#!pip3 install pytorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Загрузим необходимыe библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "from tqdm import notebook\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(seed=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0                                               text  toxic\n0           0  Explanation\\nWhy the edits made under my usern...      0\n1           1  D'aww! He matches this background colour I'm s...      0\n2           2  Hey man, I'm really not trying to edit war. It...      0\n3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n4           4  You, sir, are my hero. Any chance you remember...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>toxic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/toxic_comments.csv')\n",
    "display(df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": "None"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.info())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "0    143106\n1     16186\nName: toxic, dtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Оценим сбалансированность df\n",
    "df['toxic'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Для BERT\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Загрузим предварительно обученную модель/токенизатор\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "0         [101, 7526, 2339, 1996, 10086, 2015, 2081, 210...\n1         [101, 1040, 1005, 22091, 2860, 999, 2002, 3503...\n2         [101, 4931, 2158, 1010, 1045, 1005, 1049, 2428...\n3         [101, 1000, 2062, 1045, 2064, 1005, 1056, 2191...\n4         [101, 2017, 1010, 2909, 1010, 2024, 2026, 5394...\n                                ...                        \n159287    [101, 1000, 1024, 1024, 1024, 1024, 1024, 1998...\n159288    [101, 2017, 2323, 2022, 14984, 1997, 4426, 200...\n159289    [101, 13183, 6290, 26114, 1010, 2045, 2015, 20...\n159290    [101, 1998, 2009, 3504, 2066, 2009, 2001, 2941...\n159291    [101, 1000, 1998, 1012, 1012, 1012, 1045, 2428...\nName: text, Length: 159292, dtype: object"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = df[\"text\"].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))\n",
    "tokenized"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Искала индексы длинных предложений, чтобы потом удалить их из выдачи BERT\n",
    "# при дальнейшем обучении модели. Само удаление по too_long_rows_indexes ниже.\n",
    "\n",
    "# too_long_rows_indexes = []\n",
    "#\n",
    "# for i in notebook.tqdm(range(df.shape[0])):\n",
    "#     res = tokenizer.encode(df.loc[i, \"text\"], add_special_tokens=True)\n",
    "#     if (len(res) > 512):\n",
    "#         too_long_rows_indexes.append(i)\n",
    "#\n",
    "# too_long_rows_indexes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# len(too_long_rows_indexes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  101,  7526,  2339, ...,     0,     0,     0],\n       [  101,  1040,  1005, ...,     0,     0,     0],\n       [  101,  4931,  2158, ...,     0,     0,     0],\n       ...,\n       [  101, 13183,  6290, ...,     0,     0,     0],\n       [  101,  1998,  2009, ...,     0,     0,     0],\n       [  101,  1000,  1998, ...,     0,     0,     0]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Приведём векторы к одному размеру путем прибавления к более коротким векторам 0\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "padded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(159292, 512)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выведем размер, полученной матрицы\n",
    "np.array(padded).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(159292, 512)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим переменную, чтобы указать ей игнорировать (маскировать) заполнение, которое мы добавили\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "results_location = \"./output/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# Здесь запускала BERT батчами по 500 строк и сохраняла результаты на диск.\n",
    "# Размер батча выбирался исходя из ресурсов локального компьютера.\n",
    "# Обработка работала больше суток.\n",
    "# Оставшийся хвост не кратный 500 дочитывали отдельно, здесь это код не сохранился,\n",
    "# но это не принципиально.\n",
    "\n",
    "# batch_size = 500\n",
    "#\n",
    "# for i in notebook.tqdm(range(53, padded.shape[0] // batch_size)):\n",
    "#     batch = torch.tensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "#     attention_mask_batch = torch.tensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "#\n",
    "#     batch_features = batch_embeddings[0][:,0,:].numpy()\n",
    "#     np.savetxt(results_location + \"batch_\" + str(i) + \".csv\", batch_features, delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/319 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c40c3caa023442fb9801a3d03d7ae23f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# После того как все бачти были записаны на диск, вычитывала их в память\n",
    "# для дальнейшей обработки / составления набора фич для них.\n",
    "\n",
    "# embeddings = []\n",
    "# batch_files_names = [f for f in listdir(results_location) if isfile(join(results_location, f))]\n",
    "# batch_files_names.sort(key=lambda x: os.path.getmtime(results_location + x))\n",
    "# for i in notebook.tqdm(range(len(batch_files_names))):\n",
    "#     batch_features = np.genfromtxt(results_location + batch_files_names[i], delimiter=\",\")\n",
    "#     embeddings.append(batch_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6    \\\n0       0.220490 -0.097744 -0.073250 -0.071392 -0.085661 -0.183036  0.322567   \n1      -0.118798 -0.156563  0.238368 -0.128910 -0.122928 -0.096002  0.643840   \n2       0.075954  0.061317 -0.122162 -0.135580 -0.120700 -0.396361  0.039420   \n3      -0.027679 -0.098320  0.177464 -0.105311 -0.114202 -0.387548  0.093583   \n4      -0.116651 -0.038441 -0.080841 -0.028249 -0.014768 -0.308648  0.141258   \n...          ...       ...       ...       ...       ...       ...       ...   \n159287 -0.042763 -0.055712 -0.183988 -0.089951 -0.025618 -0.113750  0.119546   \n159288  0.024698  0.066385 -0.063861 -0.197261 -0.151639 -0.129282  0.311044   \n159289 -0.038442 -0.066573  0.042136 -0.080004 -0.034432 -0.230124  0.108003   \n159290  0.139081 -0.061743  0.048407 -0.073013 -0.020383 -0.087851  0.151391   \n159291  0.205530 -0.019716 -0.098679 -0.113771  0.170024 -0.142700  0.096606   \n\n             7         8         9    ...       758       759       760  \\\n0       0.242754 -0.038898 -0.271066  ...  0.177155 -0.026148  0.086816   \n1       0.153690 -0.207519 -0.335488  ...  0.098510 -0.217268  0.038986   \n2       0.519339 -0.130742 -0.324620  ...  0.017994 -0.276312  0.167717   \n3       0.325143 -0.159144 -0.106888  ...  0.364155 -0.030819 -0.106879   \n4       0.533530 -0.274986 -0.334551  ... -0.012091 -0.161019  0.241566   \n...          ...       ...       ...  ...       ...       ...       ...   \n159287  0.317383 -0.088454 -0.085701  ...  0.129792 -0.099137 -0.013240   \n159288  0.398141 -0.090190 -0.230817  ...  0.058604 -0.056400 -0.059040   \n159289  0.437829 -0.065173 -0.100695  ... -0.146132 -0.289016 -0.140271   \n159290  0.380969 -0.256102 -0.171124  ... -0.025120 -0.236260  0.061853   \n159291  0.304536 -0.129583 -0.323178  ...  0.071575 -0.287777  0.062330   \n\n             761       762       763       764       765       766       767  \n0      -0.171984  0.303477  0.019842 -0.199227  0.153798  0.416238  0.403389  \n1      -0.440684  0.285151 -0.148381  0.210517 -0.048998  0.543574  0.514805  \n2      -0.168578  0.155621  0.323910 -0.154194  0.106488  0.530345  0.335555  \n3      -0.193697  0.161622 -0.022145 -0.361364 -0.032484  0.349627  0.503448  \n4      -0.178456  0.210459  0.240435 -0.285982  0.031116  0.412562  0.304650  \n...          ...       ...       ...       ...       ...       ...       ...  \n159287 -0.144907 -0.119820 -0.015859 -0.037695 -0.002855  0.467618  0.370806  \n159288 -0.317960  0.187389  0.001698 -0.063733 -0.020872  0.291844  0.413866  \n159289 -0.234595 -0.146086 -0.073088 -0.129928 -0.212899  0.692907  0.256324  \n159290 -0.068619  0.191564  0.153432 -0.067029  0.034036  0.354455  0.277578  \n159291 -0.196391  0.101293  0.204140 -0.235786 -0.076580  0.302202  0.202237  \n\n[159292 rows x 768 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.220490</td>\n      <td>-0.097744</td>\n      <td>-0.073250</td>\n      <td>-0.071392</td>\n      <td>-0.085661</td>\n      <td>-0.183036</td>\n      <td>0.322567</td>\n      <td>0.242754</td>\n      <td>-0.038898</td>\n      <td>-0.271066</td>\n      <td>...</td>\n      <td>0.177155</td>\n      <td>-0.026148</td>\n      <td>0.086816</td>\n      <td>-0.171984</td>\n      <td>0.303477</td>\n      <td>0.019842</td>\n      <td>-0.199227</td>\n      <td>0.153798</td>\n      <td>0.416238</td>\n      <td>0.403389</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.118798</td>\n      <td>-0.156563</td>\n      <td>0.238368</td>\n      <td>-0.128910</td>\n      <td>-0.122928</td>\n      <td>-0.096002</td>\n      <td>0.643840</td>\n      <td>0.153690</td>\n      <td>-0.207519</td>\n      <td>-0.335488</td>\n      <td>...</td>\n      <td>0.098510</td>\n      <td>-0.217268</td>\n      <td>0.038986</td>\n      <td>-0.440684</td>\n      <td>0.285151</td>\n      <td>-0.148381</td>\n      <td>0.210517</td>\n      <td>-0.048998</td>\n      <td>0.543574</td>\n      <td>0.514805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.075954</td>\n      <td>0.061317</td>\n      <td>-0.122162</td>\n      <td>-0.135580</td>\n      <td>-0.120700</td>\n      <td>-0.396361</td>\n      <td>0.039420</td>\n      <td>0.519339</td>\n      <td>-0.130742</td>\n      <td>-0.324620</td>\n      <td>...</td>\n      <td>0.017994</td>\n      <td>-0.276312</td>\n      <td>0.167717</td>\n      <td>-0.168578</td>\n      <td>0.155621</td>\n      <td>0.323910</td>\n      <td>-0.154194</td>\n      <td>0.106488</td>\n      <td>0.530345</td>\n      <td>0.335555</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.027679</td>\n      <td>-0.098320</td>\n      <td>0.177464</td>\n      <td>-0.105311</td>\n      <td>-0.114202</td>\n      <td>-0.387548</td>\n      <td>0.093583</td>\n      <td>0.325143</td>\n      <td>-0.159144</td>\n      <td>-0.106888</td>\n      <td>...</td>\n      <td>0.364155</td>\n      <td>-0.030819</td>\n      <td>-0.106879</td>\n      <td>-0.193697</td>\n      <td>0.161622</td>\n      <td>-0.022145</td>\n      <td>-0.361364</td>\n      <td>-0.032484</td>\n      <td>0.349627</td>\n      <td>0.503448</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.116651</td>\n      <td>-0.038441</td>\n      <td>-0.080841</td>\n      <td>-0.028249</td>\n      <td>-0.014768</td>\n      <td>-0.308648</td>\n      <td>0.141258</td>\n      <td>0.533530</td>\n      <td>-0.274986</td>\n      <td>-0.334551</td>\n      <td>...</td>\n      <td>-0.012091</td>\n      <td>-0.161019</td>\n      <td>0.241566</td>\n      <td>-0.178456</td>\n      <td>0.210459</td>\n      <td>0.240435</td>\n      <td>-0.285982</td>\n      <td>0.031116</td>\n      <td>0.412562</td>\n      <td>0.304650</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159287</th>\n      <td>-0.042763</td>\n      <td>-0.055712</td>\n      <td>-0.183988</td>\n      <td>-0.089951</td>\n      <td>-0.025618</td>\n      <td>-0.113750</td>\n      <td>0.119546</td>\n      <td>0.317383</td>\n      <td>-0.088454</td>\n      <td>-0.085701</td>\n      <td>...</td>\n      <td>0.129792</td>\n      <td>-0.099137</td>\n      <td>-0.013240</td>\n      <td>-0.144907</td>\n      <td>-0.119820</td>\n      <td>-0.015859</td>\n      <td>-0.037695</td>\n      <td>-0.002855</td>\n      <td>0.467618</td>\n      <td>0.370806</td>\n    </tr>\n    <tr>\n      <th>159288</th>\n      <td>0.024698</td>\n      <td>0.066385</td>\n      <td>-0.063861</td>\n      <td>-0.197261</td>\n      <td>-0.151639</td>\n      <td>-0.129282</td>\n      <td>0.311044</td>\n      <td>0.398141</td>\n      <td>-0.090190</td>\n      <td>-0.230817</td>\n      <td>...</td>\n      <td>0.058604</td>\n      <td>-0.056400</td>\n      <td>-0.059040</td>\n      <td>-0.317960</td>\n      <td>0.187389</td>\n      <td>0.001698</td>\n      <td>-0.063733</td>\n      <td>-0.020872</td>\n      <td>0.291844</td>\n      <td>0.413866</td>\n    </tr>\n    <tr>\n      <th>159289</th>\n      <td>-0.038442</td>\n      <td>-0.066573</td>\n      <td>0.042136</td>\n      <td>-0.080004</td>\n      <td>-0.034432</td>\n      <td>-0.230124</td>\n      <td>0.108003</td>\n      <td>0.437829</td>\n      <td>-0.065173</td>\n      <td>-0.100695</td>\n      <td>...</td>\n      <td>-0.146132</td>\n      <td>-0.289016</td>\n      <td>-0.140271</td>\n      <td>-0.234595</td>\n      <td>-0.146086</td>\n      <td>-0.073088</td>\n      <td>-0.129928</td>\n      <td>-0.212899</td>\n      <td>0.692907</td>\n      <td>0.256324</td>\n    </tr>\n    <tr>\n      <th>159290</th>\n      <td>0.139081</td>\n      <td>-0.061743</td>\n      <td>0.048407</td>\n      <td>-0.073013</td>\n      <td>-0.020383</td>\n      <td>-0.087851</td>\n      <td>0.151391</td>\n      <td>0.380969</td>\n      <td>-0.256102</td>\n      <td>-0.171124</td>\n      <td>...</td>\n      <td>-0.025120</td>\n      <td>-0.236260</td>\n      <td>0.061853</td>\n      <td>-0.068619</td>\n      <td>0.191564</td>\n      <td>0.153432</td>\n      <td>-0.067029</td>\n      <td>0.034036</td>\n      <td>0.354455</td>\n      <td>0.277578</td>\n    </tr>\n    <tr>\n      <th>159291</th>\n      <td>0.205530</td>\n      <td>-0.019716</td>\n      <td>-0.098679</td>\n      <td>-0.113771</td>\n      <td>0.170024</td>\n      <td>-0.142700</td>\n      <td>0.096606</td>\n      <td>0.304536</td>\n      <td>-0.129583</td>\n      <td>-0.323178</td>\n      <td>...</td>\n      <td>0.071575</td>\n      <td>-0.287777</td>\n      <td>0.062330</td>\n      <td>-0.196391</td>\n      <td>0.101293</td>\n      <td>0.204140</td>\n      <td>-0.235786</td>\n      <td>-0.076580</td>\n      <td>0.302202</td>\n      <td>0.202237</td>\n    </tr>\n  </tbody>\n</table>\n<p>159292 rows × 768 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_embeddings = np.concatenate(embeddings)\n",
    "model_data_df = pd.DataFrame(concatenated_embeddings)\n",
    "model_data_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6    \\\n0       0.220490 -0.097744 -0.073250 -0.071392 -0.085661 -0.183036  0.322567   \n1      -0.118798 -0.156563  0.238368 -0.128910 -0.122928 -0.096002  0.643840   \n2       0.075954  0.061317 -0.122162 -0.135580 -0.120700 -0.396361  0.039420   \n3      -0.027679 -0.098320  0.177464 -0.105311 -0.114202 -0.387548  0.093583   \n4      -0.116651 -0.038441 -0.080841 -0.028249 -0.014768 -0.308648  0.141258   \n...          ...       ...       ...       ...       ...       ...       ...   \n159287 -0.042763 -0.055712 -0.183988 -0.089951 -0.025618 -0.113750  0.119546   \n159288  0.024698  0.066385 -0.063861 -0.197261 -0.151639 -0.129282  0.311044   \n159289 -0.038442 -0.066573  0.042136 -0.080004 -0.034432 -0.230124  0.108003   \n159290  0.139081 -0.061743  0.048407 -0.073013 -0.020383 -0.087851  0.151391   \n159291  0.205530 -0.019716 -0.098679 -0.113771  0.170024 -0.142700  0.096606   \n\n             7         8         9    ...       758       759       760  \\\n0       0.242754 -0.038898 -0.271066  ...  0.177155 -0.026148  0.086816   \n1       0.153690 -0.207519 -0.335488  ...  0.098510 -0.217268  0.038986   \n2       0.519339 -0.130742 -0.324620  ...  0.017994 -0.276312  0.167717   \n3       0.325143 -0.159144 -0.106888  ...  0.364155 -0.030819 -0.106879   \n4       0.533530 -0.274986 -0.334551  ... -0.012091 -0.161019  0.241566   \n...          ...       ...       ...  ...       ...       ...       ...   \n159287  0.317383 -0.088454 -0.085701  ...  0.129792 -0.099137 -0.013240   \n159288  0.398141 -0.090190 -0.230817  ...  0.058604 -0.056400 -0.059040   \n159289  0.437829 -0.065173 -0.100695  ... -0.146132 -0.289016 -0.140271   \n159290  0.380969 -0.256102 -0.171124  ... -0.025120 -0.236260  0.061853   \n159291  0.304536 -0.129583 -0.323178  ...  0.071575 -0.287777  0.062330   \n\n             761       762       763       764       765       766       767  \n0      -0.171984  0.303477  0.019842 -0.199227  0.153798  0.416238  0.403389  \n1      -0.440684  0.285151 -0.148381  0.210517 -0.048998  0.543574  0.514805  \n2      -0.168578  0.155621  0.323910 -0.154194  0.106488  0.530345  0.335555  \n3      -0.193697  0.161622 -0.022145 -0.361364 -0.032484  0.349627  0.503448  \n4      -0.178456  0.210459  0.240435 -0.285982  0.031116  0.412562  0.304650  \n...          ...       ...       ...       ...       ...       ...       ...  \n159287 -0.144907 -0.119820 -0.015859 -0.037695 -0.002855  0.467618  0.370806  \n159288 -0.317960  0.187389  0.001698 -0.063733 -0.020872  0.291844  0.413866  \n159289 -0.234595 -0.146086 -0.073088 -0.129928 -0.212899  0.692907  0.256324  \n159290 -0.068619  0.191564  0.153432 -0.067029  0.034036  0.354455  0.277578  \n159291 -0.196391  0.101293  0.204140 -0.235786 -0.076580  0.302202  0.202237  \n\n[159292 rows x 768 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.220490</td>\n      <td>-0.097744</td>\n      <td>-0.073250</td>\n      <td>-0.071392</td>\n      <td>-0.085661</td>\n      <td>-0.183036</td>\n      <td>0.322567</td>\n      <td>0.242754</td>\n      <td>-0.038898</td>\n      <td>-0.271066</td>\n      <td>...</td>\n      <td>0.177155</td>\n      <td>-0.026148</td>\n      <td>0.086816</td>\n      <td>-0.171984</td>\n      <td>0.303477</td>\n      <td>0.019842</td>\n      <td>-0.199227</td>\n      <td>0.153798</td>\n      <td>0.416238</td>\n      <td>0.403389</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.118798</td>\n      <td>-0.156563</td>\n      <td>0.238368</td>\n      <td>-0.128910</td>\n      <td>-0.122928</td>\n      <td>-0.096002</td>\n      <td>0.643840</td>\n      <td>0.153690</td>\n      <td>-0.207519</td>\n      <td>-0.335488</td>\n      <td>...</td>\n      <td>0.098510</td>\n      <td>-0.217268</td>\n      <td>0.038986</td>\n      <td>-0.440684</td>\n      <td>0.285151</td>\n      <td>-0.148381</td>\n      <td>0.210517</td>\n      <td>-0.048998</td>\n      <td>0.543574</td>\n      <td>0.514805</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.075954</td>\n      <td>0.061317</td>\n      <td>-0.122162</td>\n      <td>-0.135580</td>\n      <td>-0.120700</td>\n      <td>-0.396361</td>\n      <td>0.039420</td>\n      <td>0.519339</td>\n      <td>-0.130742</td>\n      <td>-0.324620</td>\n      <td>...</td>\n      <td>0.017994</td>\n      <td>-0.276312</td>\n      <td>0.167717</td>\n      <td>-0.168578</td>\n      <td>0.155621</td>\n      <td>0.323910</td>\n      <td>-0.154194</td>\n      <td>0.106488</td>\n      <td>0.530345</td>\n      <td>0.335555</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.027679</td>\n      <td>-0.098320</td>\n      <td>0.177464</td>\n      <td>-0.105311</td>\n      <td>-0.114202</td>\n      <td>-0.387548</td>\n      <td>0.093583</td>\n      <td>0.325143</td>\n      <td>-0.159144</td>\n      <td>-0.106888</td>\n      <td>...</td>\n      <td>0.364155</td>\n      <td>-0.030819</td>\n      <td>-0.106879</td>\n      <td>-0.193697</td>\n      <td>0.161622</td>\n      <td>-0.022145</td>\n      <td>-0.361364</td>\n      <td>-0.032484</td>\n      <td>0.349627</td>\n      <td>0.503448</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.116651</td>\n      <td>-0.038441</td>\n      <td>-0.080841</td>\n      <td>-0.028249</td>\n      <td>-0.014768</td>\n      <td>-0.308648</td>\n      <td>0.141258</td>\n      <td>0.533530</td>\n      <td>-0.274986</td>\n      <td>-0.334551</td>\n      <td>...</td>\n      <td>-0.012091</td>\n      <td>-0.161019</td>\n      <td>0.241566</td>\n      <td>-0.178456</td>\n      <td>0.210459</td>\n      <td>0.240435</td>\n      <td>-0.285982</td>\n      <td>0.031116</td>\n      <td>0.412562</td>\n      <td>0.304650</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>159287</th>\n      <td>-0.042763</td>\n      <td>-0.055712</td>\n      <td>-0.183988</td>\n      <td>-0.089951</td>\n      <td>-0.025618</td>\n      <td>-0.113750</td>\n      <td>0.119546</td>\n      <td>0.317383</td>\n      <td>-0.088454</td>\n      <td>-0.085701</td>\n      <td>...</td>\n      <td>0.129792</td>\n      <td>-0.099137</td>\n      <td>-0.013240</td>\n      <td>-0.144907</td>\n      <td>-0.119820</td>\n      <td>-0.015859</td>\n      <td>-0.037695</td>\n      <td>-0.002855</td>\n      <td>0.467618</td>\n      <td>0.370806</td>\n    </tr>\n    <tr>\n      <th>159288</th>\n      <td>0.024698</td>\n      <td>0.066385</td>\n      <td>-0.063861</td>\n      <td>-0.197261</td>\n      <td>-0.151639</td>\n      <td>-0.129282</td>\n      <td>0.311044</td>\n      <td>0.398141</td>\n      <td>-0.090190</td>\n      <td>-0.230817</td>\n      <td>...</td>\n      <td>0.058604</td>\n      <td>-0.056400</td>\n      <td>-0.059040</td>\n      <td>-0.317960</td>\n      <td>0.187389</td>\n      <td>0.001698</td>\n      <td>-0.063733</td>\n      <td>-0.020872</td>\n      <td>0.291844</td>\n      <td>0.413866</td>\n    </tr>\n    <tr>\n      <th>159289</th>\n      <td>-0.038442</td>\n      <td>-0.066573</td>\n      <td>0.042136</td>\n      <td>-0.080004</td>\n      <td>-0.034432</td>\n      <td>-0.230124</td>\n      <td>0.108003</td>\n      <td>0.437829</td>\n      <td>-0.065173</td>\n      <td>-0.100695</td>\n      <td>...</td>\n      <td>-0.146132</td>\n      <td>-0.289016</td>\n      <td>-0.140271</td>\n      <td>-0.234595</td>\n      <td>-0.146086</td>\n      <td>-0.073088</td>\n      <td>-0.129928</td>\n      <td>-0.212899</td>\n      <td>0.692907</td>\n      <td>0.256324</td>\n    </tr>\n    <tr>\n      <th>159290</th>\n      <td>0.139081</td>\n      <td>-0.061743</td>\n      <td>0.048407</td>\n      <td>-0.073013</td>\n      <td>-0.020383</td>\n      <td>-0.087851</td>\n      <td>0.151391</td>\n      <td>0.380969</td>\n      <td>-0.256102</td>\n      <td>-0.171124</td>\n      <td>...</td>\n      <td>-0.025120</td>\n      <td>-0.236260</td>\n      <td>0.061853</td>\n      <td>-0.068619</td>\n      <td>0.191564</td>\n      <td>0.153432</td>\n      <td>-0.067029</td>\n      <td>0.034036</td>\n      <td>0.354455</td>\n      <td>0.277578</td>\n    </tr>\n    <tr>\n      <th>159291</th>\n      <td>0.205530</td>\n      <td>-0.019716</td>\n      <td>-0.098679</td>\n      <td>-0.113771</td>\n      <td>0.170024</td>\n      <td>-0.142700</td>\n      <td>0.096606</td>\n      <td>0.304536</td>\n      <td>-0.129583</td>\n      <td>-0.323178</td>\n      <td>...</td>\n      <td>0.071575</td>\n      <td>-0.287777</td>\n      <td>0.062330</td>\n      <td>-0.196391</td>\n      <td>0.101293</td>\n      <td>0.204140</td>\n      <td>-0.235786</td>\n      <td>-0.076580</td>\n      <td>0.302202</td>\n      <td>0.202237</td>\n    </tr>\n  </tbody>\n</table>\n<p>159292 rows × 768 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0         0\n1         0\n2         0\n3         0\n4         0\n         ..\n159287    0\n159288    0\n159289    0\n159290    0\n159291    0\nName: toxic, Length: 159292, dtype: int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Выделим целевой признак\n",
    "features = model_data_df\n",
    "target = df['toxic']\n",
    "\n",
    "display(features)\n",
    "display(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 768)\n",
      "(159292,)\n"
     ]
    }
   ],
   "source": [
    "# Пробовала удалять по индексам предложения, которые при токенизации выходили за лимиты\n",
    "# предобученной модели BERT (512), но это дало незначительный прирост метрики приблизительно ~0.01.\n",
    "# Скорее всего из-за того, что таких предложений было мало всего около 2%.\n",
    "\n",
    "# features = features.drop(too_long_rows_indexes) # удаление длинных предложений\n",
    "# target = target.drop(too_long_rows_indexes)\n",
    "\n",
    "features.reset_index(drop=True, inplace=True)\n",
    "target.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Разделим данные на 2 выборки: обучающуюся, тестовую 75:25\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25)\n",
    "\n",
    "features_train.reset_index(drop=True, inplace=True)\n",
    "features_test.reset_index(drop=True, inplace=True)\n",
    "target_train.reset_index(drop=True, inplace=True)\n",
    "target_test.reset_index(drop=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('classification', DummyClassifier())])",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;classification&#x27;, DummyClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classification&#x27;, DummyClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier()</pre></div></div></div></div></div></div></div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создадим pipeline\n",
    "pipeline = make_pipeline()\n",
    "pipeline.steps.append(('classification', DummyClassifier()))\n",
    "pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def create_randomized_search_cv(pipeline, iterations_count, parameters=None):\n",
    "    if parameters is None:\n",
    "        params = [\n",
    "            {\n",
    "                'classification': [SGDClassifier()],\n",
    "                'classification__alpha': [1, 1e-01, 1e-02, 1e-03, 1e-04, 1e-05, 1e-06],\n",
    "                 'classification__penalty': ['l1','l2'],\n",
    "\n",
    "            },\n",
    "\n",
    "            {\n",
    "                'classification': [LinearSVC()],\n",
    "                'classification__max_iter': [1000, 2000, 100],\n",
    "                'classification__C': [0.1, 1, 10, 100],\n",
    "            },\n",
    "            {\n",
    "                'classification': [LogisticRegression()],\n",
    "                'classification__C': [0.001, 0.01, 0.1, 1, 10, 50, 100, 200],\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        params = parameters\n",
    "\n",
    "    grid = RandomizedSearchCV(pipeline,\n",
    "                              params,\n",
    "                              n_iter = iterations_count,\n",
    "                              cv = 3,\n",
    "                              scoring = 'f1',\n",
    "                              n_jobs=-1)\n",
    "\n",
    "    return grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('classification',\n                                              DummyClassifier())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions=[{'classification': [SGDClassifier()],\n                                         'classification__alpha': [1, 0.1, 0.01,\n                                                                   0.001,\n                                                                   0.0001,\n                                                                   1e-05,\n                                                                   1e-06],\n                                         'classification__penalty': ['l1',\n                                                                     'l2']},\n                                        {'classification': [LinearSVC()],\n                                         'classification__C': [0.1, 1, 10, 100],\n                                         'classification__max_iter': [1000,\n                                                                      2000,\n                                                                      100]},\n                                        {'classification': [LogisticRegression()],\n                                         'classification__C': [0.001, 0.01, 0.1,\n                                                               1, 10, 50, 100,\n                                                               200]}],\n                   scoring='f1')",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;classification&#x27;,\n                                              DummyClassifier())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions=[{&#x27;classification&#x27;: [SGDClassifier()],\n                                         &#x27;classification__alpha&#x27;: [1, 0.1, 0.01,\n                                                                   0.001,\n                                                                   0.0001,\n                                                                   1e-05,\n                                                                   1e-06],\n                                         &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;,\n                                                                     &#x27;l2&#x27;]},\n                                        {&#x27;classification&#x27;: [LinearSVC()],\n                                         &#x27;classification__C&#x27;: [0.1, 1, 10, 100],\n                                         &#x27;classification__max_iter&#x27;: [1000,\n                                                                      2000,\n                                                                      100]},\n                                        {&#x27;classification&#x27;: [LogisticRegression()],\n                                         &#x27;classification__C&#x27;: [0.001, 0.01, 0.1,\n                                                               1, 10, 50, 100,\n                                                               200]}],\n                   scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;classification&#x27;,\n                                              DummyClassifier())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions=[{&#x27;classification&#x27;: [SGDClassifier()],\n                                         &#x27;classification__alpha&#x27;: [1, 0.1, 0.01,\n                                                                   0.001,\n                                                                   0.0001,\n                                                                   1e-05,\n                                                                   1e-06],\n                                         &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;,\n                                                                     &#x27;l2&#x27;]},\n                                        {&#x27;classification&#x27;: [LinearSVC()],\n                                         &#x27;classification__C&#x27;: [0.1, 1, 10, 100],\n                                         &#x27;classification__max_iter&#x27;: [1000,\n                                                                      2000,\n                                                                      100]},\n                                        {&#x27;classification&#x27;: [LogisticRegression()],\n                                         &#x27;classification__C&#x27;: [0.001, 0.01, 0.1,\n                                                               1, 10, 50, 100,\n                                                               200]}],\n                   scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classification&#x27;, DummyClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = create_randomized_search_cv(pipeline, 100)\n",
    "grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 48s\n",
      "Wall time: 20min 35s\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[('classification',\n                                              DummyClassifier())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions=[{'classification': [SGDClassifier()],\n                                         'classification__alpha': [1, 0.1, 0.01,\n                                                                   0.001,\n                                                                   0.0001,\n                                                                   1e-05,\n                                                                   1e-06],\n                                         'classification__penalty': ['l1',\n                                                                     'l2']},\n                                        {'classification': [LinearSVC(C=1,\n                                                                      max_iter=2000)],\n                                         'classification__C': [0.1, 1, 10, 100],\n                                         'classification__max_iter': [1000,\n                                                                      2000,\n                                                                      100]},\n                                        {'classification': [LogisticRegression()],\n                                         'classification__C': [0.001, 0.01, 0.1,\n                                                               1, 10, 50, 100,\n                                                               200]}],\n                   scoring='f1')",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;classification&#x27;,\n                                              DummyClassifier())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions=[{&#x27;classification&#x27;: [SGDClassifier()],\n                                         &#x27;classification__alpha&#x27;: [1, 0.1, 0.01,\n                                                                   0.001,\n                                                                   0.0001,\n                                                                   1e-05,\n                                                                   1e-06],\n                                         &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;,\n                                                                     &#x27;l2&#x27;]},\n                                        {&#x27;classification&#x27;: [LinearSVC(C=1,\n                                                                      max_iter=2000)],\n                                         &#x27;classification__C&#x27;: [0.1, 1, 10, 100],\n                                         &#x27;classification__max_iter&#x27;: [1000,\n                                                                      2000,\n                                                                      100]},\n                                        {&#x27;classification&#x27;: [LogisticRegression()],\n                                         &#x27;classification__C&#x27;: [0.001, 0.01, 0.1,\n                                                               1, 10, 50, 100,\n                                                               200]}],\n                   scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n                   estimator=Pipeline(steps=[(&#x27;classification&#x27;,\n                                              DummyClassifier())]),\n                   n_iter=100, n_jobs=-1,\n                   param_distributions=[{&#x27;classification&#x27;: [SGDClassifier()],\n                                         &#x27;classification__alpha&#x27;: [1, 0.1, 0.01,\n                                                                   0.001,\n                                                                   0.0001,\n                                                                   1e-05,\n                                                                   1e-06],\n                                         &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;,\n                                                                     &#x27;l2&#x27;]},\n                                        {&#x27;classification&#x27;: [LinearSVC(C=1,\n                                                                      max_iter=2000)],\n                                         &#x27;classification__C&#x27;: [0.1, 1, 10, 100],\n                                         &#x27;classification__max_iter&#x27;: [1000,\n                                                                      2000,\n                                                                      100]},\n                                        {&#x27;classification&#x27;: [LogisticRegression()],\n                                         &#x27;classification__C&#x27;: [0.001, 0.01, 0.1,\n                                                               1, 10, 50, 100,\n                                                               200]}],\n                   scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;classification&#x27;, DummyClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid.fit(features_train, target_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "{'classification__max_iter': 2000,\n 'classification__C': 1,\n 'classification': LinearSVC(C=1, max_iter=2000)}"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим лучшие параметры\n",
    "grid.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7416498753059999"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посмотрим получившуюся лучшую метрику на обучающейся выборке\n",
    "grid.best_score_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Посчитаем предсказания на тестовой выборке\n",
    "predictions = grid.predict(features_test)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7357395612172682"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_test = f1_score(target_test, predictions)\n",
    "f1_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
